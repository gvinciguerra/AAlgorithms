\section{Randomized min-cut algorithm}

Consider the randomized min-cut algorithm discussed in class. We have seen that its probability of success is at least $1/{n \choose 2}$, where $n$ is the number of its vertices.
\begin{itemize}
  \item Describe how to implement the algorithm when the graph is represented by adjacency lists, and analyze its running time. In particular, a contraction step can be done in $O(n)$ time.
  \item A weighted graph has a weight $w(e)$ on each edge $e$, which is a positive real number. The min-cut in this case is meant to be min-weighted cut, where the sum of the weights in the cut edges is minimum. Describe how to extend the algorithm to weighted graphs, and show that the probability of success is still $\geq 1/{n \choose 2}$ [hint: define the weighted degree of a node].
  \item Show that running the algorithm multiple times independently at random, and taking the minimum among the min-cuts thus produced, the probability of success can be made at least $1 - 1/n^c$ for a constant $c > 0$ (hence, with high probability).
\end{itemize}

\vspace{0.5cm}
\paragraph{Contraction step.} We assume that the adjacency lists $Adj[x]$ are sorted $\forall x \in V$. We also note that the multigraph is undirected, therefore $v\in Adj[u]$ if and only if $u\in Adj[v]$. We maintain an attribute $pe$ in each edge to store the number of parallel edges.

To contract an edge $(u, v)$, we have to merge the two adjacency lists $Adj[u]$ and $Adj[v]$ into a single \emph{sorted} adjacency list $Adj[uv]$ --- like the merge procedure in merge sort --- ensuring that:
\begin{itemize}
  \item if the current node in $Adj[u]$ is $v$, skip the node, since it will not appear in $Adj[uv]$ (do the same with $Adj[v]$ and $u$);
  \item if the current nodes are equal to $x$, add $x$ to $Adj[uv]$ and set $(uv, x).pe = (u,x).pe + (v,x).pe$.
\end{itemize}
Finally, we replace $Adj[u]$ and $Adj[v]$ with the newly created $Adj[uv]$. The total cost of this step is $O(n)$.

\paragraph{Weighted graph extension.}
We now extend the above to weighted multi-graph by re-conducting it to the non-weighted case.
First we'll define the \emph{min-weighted cut}, the weighted cut where $\min_{|c| > 0} C = \min_{C} \sum{\omega(c)}$, that is the sum of the weights determines the weight of the overall cut.
We then have the weight for the overall graph: 
\begin{equation*}
\omega_G = \sum^{n}\left( \omega(n) \right)
\end{equation*}
and for the min cut: $\omega_{min}$.
Similarly as we've seen in class we can define $\omega_G$ in function of $\omega_{min}$:
\begin{equation*}
\omega_G = \frac{\sum^{n} \left( \omega(n) \right)}{2} = \frac{n \cdot \omega_{min}}{2}
\end{equation*}

Giving us an error probability of
\begin{equation*}
\Pr(error) = \frac{\textsc{weight(min-cut)}}{\textsc{weight(graph)}} = \frac{\omega_{min}}{\omega_G} = \frac{\omega_{min}}{\frac{n \cdot \omega_{min}}{2}} = \frac{2}{n}
\end{equation*}
That is, we reach the same error probability seen in class.
Therefore we can safely assume that the analysis is the same.

The algorithm does not need to be edited but in the computation of the min cut, which is now $\omega_c$ and not $\sum^{e^{i, j}} \left( e_i \right)$ where $e_i$ is an edge between $i, j$ last remaining nodes in the cut.

\paragraph{Error probability.}
By the analysis seen in class we have an error probability of
\begin{equation*}
1 - \Pr({\text{success}}) = 1 - \frac{1}{{{n} \choose {1}}}
\end{equation*}
if we then run the algorithm some $d \cdot \frac{1}{{{n} \choose {2}}}$ times, the probability of success becomes
\begin{equation*}
1 - \left(1 - \frac{1}{{{n} \choose {2}}} \right)^{c \cdot \frac{1}{{{n} \choose {2}}}} \geq 1 - e^{d}
\end{equation*}
by $d = c \ln(c)$ we have an error probability of $\leq \frac{1}{n^c}$.